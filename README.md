# Maria QuitÃ©ria

![](https://gitlab.com/anapaulagomes/maria-quiteria/badges/master/pipeline.svg)

Um projeto para libertar dados do municÃ­pio de [Feira de Santana](https://pt.wikipedia.org/wiki/Feira_de_Santana).

## Bases de Dados

| Base de dados | Fonte | DescriÃ§Ã£o        | Status           | Download |
| ------------- | ------------- | ------------- |:-------------:|:-----:|
| Agenda (`citycouncil.py`) | CÃ¢mara Municipal | Coleta agenda da CÃ¢mara Municipal. | âœ… | ğŸ”œ |
| Contratos (`cityhall.py`) | Prefeitura | Contratos realizados pela prefeitura entre 2016 e 2017. | âœ… | ğŸ”œ |
| DiÃ¡rio Oficial (`gazette.py`) | Prefeitura/CÃ¢mara de Vereadores | DiÃ¡rio oficial do executivo e legislativo desde 2015. | âœ… | ğŸ”œ |
| DiÃ¡rio Oficial (legado - antes de 2015) (`gazette.py`) | Prefeitura | Leis e decretos entre 1999 e 2015. | âœ… | ğŸ”œ |
| LicitaÃ§Ãµes (`cityhall.py`) | Prefeitura | LicitaÃ§Ãµes realizadas pela prefeitura desde 2015. | âœ… | ğŸ”œ |
| Pagamentos (`cityhall.py`) | Prefeitura | Pagamentos realizados pela prefeitura desde 2010. | âœ… | [Kaggle](https://www.kaggle.com/anapaulagomes/pagamentos-da-prefeitura-de-feira-de-santana) |

## Coleta

### Docker

Prepare seu ambiente:

```bash
docker-compose pull
docker-compose build
```

Execute os testes:

```bash
docker-compose run --rm scraper pytest
```

Execute os spiders:

```bash
docker-compose run --rm scraper bash -c "cd scraper && python runner.py"  # dia anterior
docker-compose run --rm scraper bash -c "cd scraper && python runner.py --all"  # todos desde data inicial

```

Execute um spider em especÃ­fico:

```bash
docker-compose run --rm scraper bash -c "cd scraper && scrapy crawl <nome-do-spider>"
```

### Local

Para rodar esse projeto localmente, instale as dependÃªncias:

```bash
pip install -r dev_requirements.txt
```

E tenha o [Apache Tika](https://tika.apache.org/download.html) instalado.
Ele vai extrair o texto dos PDFs.

No diretÃ³rio `scraper` vocÃª poderÃ¡ encontrar os _spiders_ responsÃ¡veis pela
coleta dos dados. Para entender melhor como eles funcionam, dÃª uma olhada
na documentaÃ§Ã£o do [scrapy](https://docs.scrapy.org/).

Para executar todos os _spiders_, desde o inÃ­cio execute:

```
cd scraper && python runner.py --all
```

Para executar todos os _spiders_, coletando apenas o dia anterior:

```
cd scraper && python runner.py
```

Para executar um _spider_, execute:

```
cd scraper && scrapy crawl payments
```

Para salvar os dados de um _spider_:

```
cd scraper && scrapy crawl payments -o pagamentos.json
```

VocÃª pode substituir `json` por outros formatos como `csv`.

----

NÃ£o sabe quem foi [Maria QuitÃ©ria](https://pt.wikipedia.org/wiki/Maria_Quit%C3%A9ria)?

----

## Agradecimentos

Ao [Querido DiÃ¡rio](https://github.com/okfn-brasil/diario-oficial),
fonte de inspiraÃ§Ã£o cÃ­vica e tecnolÃ³gica.
